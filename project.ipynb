{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f878af7d",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a3939",
   "metadata": {},
   "source": [
    "### 1. Load the data from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f3d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from \n",
    "ds = load_dataset(\"MedRAG/pubmed\")\n",
    "\n",
    "# Get the train dataï¼Œ first 20k samples\n",
    "train_data = ds['train']\n",
    "\n",
    "df = pd.DataFrame(train_data[:20000])\n",
    "\n",
    "# Save the whole train data to a csv file\n",
    "df.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571325e2",
   "metadata": {},
   "source": [
    "### 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d84002",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313cd0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.iloc[0]['contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78561808",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data_raw.iloc[0]['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw['contents'].apply(lambda x: len(x.split(' '))).plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_df(doc=doc):\n",
    "    token_info = []\n",
    "    for token in doc:\n",
    "        token_info.append({\n",
    "            \"Text\": token.text,\n",
    "            \"Index\": token.idx,\n",
    "            \"Whitespace\": token.is_space,\n",
    "            \"Is Alphanumeric?\": token.is_alpha,\n",
    "            \"Is Punctuation?\": token.is_punct,\n",
    "            \"Is Stop Word?\": token.is_stop\n",
    "        })\n",
    "    return pd.DataFrame(token_info)\n",
    "\n",
    "token_to_df(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d75304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    complete_doc = nlp(text)\n",
    "    words = [token.text for token in complete_doc \n",
    "             if token.is_alpha and not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def lemmalize_text(text):\n",
    "    complete_doc = nlp(text)\n",
    "    words = [token.lemma_ for token in complete_doc]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceacb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data_raw.iloc[0]['contents']\n",
    "text = clean_text(text)\n",
    "text = lemmalize_text(text)\n",
    "clean_doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_df(clean_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if str(token) != str(token.lemma_):\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_text(text):\n",
    "    complete_doc = nlp(text)\n",
    "    words = [token.text.lower() for token in complete_doc]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = data_raw.loc[:, 'contents'].apply(clean_text).apply(lemmalize_text).apply(tokenized_text)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.apply(lambda x: len(x)).plot(kind='hist', bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
