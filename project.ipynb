{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f878af7d",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a3939",
   "metadata": {},
   "source": [
    "### 1. Load the data from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f3d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from \n",
    "ds = load_dataset(\"MedRAG/pubmed\")\n",
    "\n",
    "# Get the train dataï¼Œ first 20k samples\n",
    "train_data = ds['train']\n",
    "\n",
    "df = pd.DataFrame(train_data[:20000])\n",
    "\n",
    "# Save the whole train data to a csv file\n",
    "df.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571325e2",
   "metadata": {},
   "source": [
    "### 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bc6fd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m nlp = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men_core_web_sm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Code\\RAG\\rag_env\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     28\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     29\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     35\u001b[39m ) -> Language:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Code\\RAG\\rag_env\\Lib\\site-packages\\spacy\\util.py:472\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E050.format(name=name))\n",
      "\u001b[31mOSError\u001b[39m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d84002",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313cd0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.iloc[0]['contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78561808",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(data_raw.iloc[0]['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw['contents'].apply(lambda x: len(x.split(' '))).plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_df(doc=doc):\n",
    "    token_info = []\n",
    "    for token in doc:\n",
    "        token_info.append({\n",
    "            \"Text\": token.text,\n",
    "            \"Index\": token.idx,\n",
    "            \"Whitespace\": token.is_space,\n",
    "            \"Is Alphanumeric?\": token.is_alpha,\n",
    "            \"Is Punctuation?\": token.is_punct,\n",
    "            \"Is Stop Word?\": token.is_stop\n",
    "        })\n",
    "    return pd.DataFrame(token_info)\n",
    "\n",
    "token_to_df(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d75304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    complete_doc = nlp(text)\n",
    "    words = [token.text for token in complete_doc \n",
    "             if token.is_alpha and not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def lemmalize_text(text):\n",
    "    complete_doc = nlp(text)\n",
    "    words = [token.lemma_ for token in complete_doc]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceacb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data_raw.iloc[0]['contents']\n",
    "text = clean_text(text)\n",
    "text = lemmalize_text(text)\n",
    "clean_doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_df(clean_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if str(token) != str(token.lemma_):\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_text(text):\n",
    "    complete_doc = nlp(text)\n",
    "    words = [token.text.lower() for token in complete_doc]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = data_raw.loc[:, 'contents'].apply(clean_text).apply(lemmalize_text).apply(tokenized_text)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.apply(lambda x: len(x)).plot(kind='hist', bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
